# ğŸ—ï¸ Service Architecture & Data Flow Documentation

## ğŸ“Š System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ORALIA AI SCRAPING SERVICE                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   USER LAYER    â”‚    â”‚  APPLICATION    â”‚    â”‚        AWS CLOUD               â”‚
â”‚                 â”‚    â”‚     LAYER       â”‚    â”‚                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  React    â”‚â—„â”€â”¼â”€â”€â”€â”€â”¼â”€â–ºâ”‚  Express  â”‚â—„â”€â”¼â”€â”€â”€â”€â”¼â”€â–ºâ”‚   S3    â”‚  â”‚   Bedrock   â”‚  â”‚
â”‚  â”‚ Frontend  â”‚  â”‚    â”‚  â”‚   API     â”‚  â”‚    â”‚  â”‚ Storage â”‚  â”‚ Knowledge   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    Base     â”‚  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Dashboard â”‚  â”‚    â”‚  â”‚ Scraping  â”‚  â”‚    â”‚  â”‚OpenSearchâ”‚  â”‚  Foundation â”‚  â”‚
â”‚  â”‚    UI     â”‚  â”‚    â”‚  â”‚ Services  â”‚  â”‚    â”‚  â”‚  Vector  â”‚  â”‚   Models    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    â”‚  â”‚  Index   â”‚  â”‚    (LLMs)   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Complete Data Flow Process

### Phase 1: User Interaction & Request Processing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Input â”‚ â”€â”€â–º â”‚  Frontend   â”‚ â”€â”€â–º â”‚   API       â”‚ â”€â”€â–º â”‚ Validation  â”‚
â”‚    (URL)    â”‚     â”‚ Validation  â”‚     â”‚ Endpoint    â”‚     â”‚ Middleware  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼                   â–¼
   ğŸ“ "Enter URL"     ğŸ” "Check format"   ğŸŒ "POST /api/       âœ… "Validate &
   to scrape data     validate domain     scraping/crawl"     sanitize input"
```

### Phase 2: URL Discovery & Site Mapping

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Base URL    â”‚ â”€â”€â–º â”‚ Sitemap     â”‚ â”€â”€â–º â”‚ Robots.txt  â”‚ â”€â”€â–º â”‚ Internal    â”‚
â”‚ Processing  â”‚     â”‚ Discovery   â”‚     â”‚ Analysis    â”‚     â”‚ Link Crawl  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼                   â–¼
   ğŸ¯ Parse domain    ğŸ—ºï¸ "/sitemap.xml"   ğŸ¤– "/robots.txt"   ğŸ•·ï¸ Extract all
   extract hostname   "/sitemap_index"    find sitemaps      internal links
                     parse XML structure                     from main pages

                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  URL Collection â”‚
                     â”‚ & Deduplication â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        ğŸ“Š Final URL list
                        filter & prioritize
```

### Phase 3: Content Extraction Engine

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Puppeteer   â”‚ â”€â”€â–º â”‚ Page Load   â”‚ â”€â”€â–º â”‚ Dynamic     â”‚ â”€â”€â–º â”‚ Content     â”‚
â”‚ Browser     â”‚     â”‚ & Render    â”‚     â”‚ Content     â”‚     â”‚ Extraction  â”‚
â”‚ Launch      â”‚     â”‚             â”‚     â”‚ Loading     â”‚     â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼                   â–¼
   ğŸ¤– Headless        ğŸŒ Navigate to     â³ Scroll, wait      ğŸ“„ Parse HTML
   Chrome instance    page with full     for lazy loading    with Cheerio
   optimized args     wait conditions    handle popups       clean & extract

                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ 18+ Extractors  â”‚
                     â”‚    Parallel     â”‚
                     â”‚   Processing    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  CONTENT EXTRACTION                          â”‚
    â”‚                                                              â”‚
    â”‚  ğŸ›ï¸ Products    ğŸ’° Pricing    ğŸ”§ Services   ğŸ“… Events      â”‚
    â”‚  â­ Reviews     ğŸ–¼ï¸ Media       ğŸ“Š Tables     ğŸ“ Text       â”‚
    â”‚  ğŸ¢ Contacts    ğŸ“ Locations   ğŸ¯ Features   ğŸ“‹ Forms       â”‚
    â”‚  ğŸ³ Recipes     ğŸ“š Courses     ğŸ’¼ Jobs       ğŸª Events      â”‚
    â”‚  ğŸ¬ Articles    ğŸ“± Apps        ğŸ† Awards     ğŸ“ˆ Analytics   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Phase 4: Data Processing & Structuring

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Raw Data    â”‚ â”€â”€â–º â”‚ Cleaning &  â”‚ â”€â”€â–º â”‚ Structured  â”‚ â”€â”€â–º â”‚ Chunk       â”‚
â”‚ Collection  â”‚     â”‚ Validation  â”‚     â”‚ Data Format â”‚     â”‚ Creation    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼                   â–¼
   ğŸ“Š All extracted   ğŸ§¹ Remove noise    ğŸ—ï¸ Organize by    âœ‚ï¸ Split into
   data from all      normalize text     content type      searchable chunks
   18+ extractors     validate formats   create schemas    with metadata

                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Hash Generation â”‚
                     â”‚ & Deduplication â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        ğŸ” SHA256 hashing
                        content versioning
                        duplicate detection
```

### Phase 5: AWS Storage Architecture

```
                           ğŸ—ï¸ S3 STORAGE HIERARCHY
                                      â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                         â”‚                         â”‚
            â–¼                         â–¼                         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Raw Content â”‚         â”‚ Processed   â”‚         â”‚ Structured  â”‚
    â”‚   Storage   â”‚         â”‚   Content   â”‚         â”‚    Data     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                         â”‚                         â”‚
            â–¼                         â–¼                         â–¼
    ğŸ“„ raw/domain/         âš¡ processed/           ğŸ—ï¸ structured/
    date/hash_raw.html     domain/date/           domain/date/
                          hash_processed.json     hash_products.json
                                                 hash_pricing.json
                                                 hash_services.json

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Media Data  â”‚         â”‚ Table Data  â”‚         â”‚ Metadata    â”‚
    â”‚   Storage   â”‚         â”‚   Storage   â”‚         â”‚   Storage   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                         â”‚                         â”‚
            â–¼                         â–¼                         â–¼
    ğŸ¨ media/domain/       ğŸ“Š tables/domain/      ğŸ“‹ metadata/domain/
    date/hash_media.json   date/hash_tables.json  date/hash_metadata.json
                                                  date/scraping-log.json
```

### Phase 6: Knowledge Base Integration

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ S3 Storage  â”‚ â”€â”€â–º â”‚ Bedrock     â”‚ â”€â”€â–º â”‚ Vector      â”‚ â”€â”€â–º â”‚ OpenSearch  â”‚
â”‚ Trigger     â”‚     â”‚ Ingestion   â”‚     â”‚ Embedding   â”‚     â”‚ Index       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼                   â–¼
   ğŸ“¤ New content     ğŸ§  Foundation      ğŸ§® Convert text     ğŸ” Store vectors
   uploaded to S3     Model processing  to numerical        in searchable
   triggers sync      chunk analysis    representations     vector database

                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚  Knowledge Base â”‚
                     â”‚     Ready       â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        âœ… Content indexed
                        ready for queries
```

### Phase 7: Query & Response Generation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User Query  â”‚ â”€â”€â–º â”‚ Vector      â”‚ â”€â”€â–º â”‚ Context     â”‚ â”€â”€â–º â”‚ AI Response â”‚
â”‚ Processing  â”‚     â”‚ Search      â”‚     â”‚ Retrieval   â”‚     â”‚ Generation  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                   â”‚                   â”‚                   â”‚
       â–¼                   â–¼                   â–¼                   â–¼
   ğŸ’¬ "What products   ğŸ” Find similar    ğŸ“š Retrieve top    ğŸ¤– Generate answer
   are available?"     vectors in         5 relevant         with context using
   convert to vector   OpenSearch index   chunks from KB     Claude/GPT model

                               â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚ Formatted       â”‚
                     â”‚ Response        â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        ğŸ’¬ JSON response
                        with citations
                        and confidence
```

---

## ğŸ”§ Service Component Architecture

### Core Services Breakdown

```
ğŸ“¦ SCRAPING SERVICE LAYER
â”œâ”€â”€ ğŸ•·ï¸ ScrapingService.js
â”‚   â”œâ”€â”€ scrapeSinglePage()           # Single URL processing
â”‚   â”œâ”€â”€ crawlAndScrapeWebsite()      # Full website crawling
â”‚   â”œâ”€â”€ extractContent()             # Content extraction orchestrator
â”‚   â”œâ”€â”€ extractProducts()            # Product information extraction
â”‚   â”œâ”€â”€ extractPricing()             # Pricing data extraction
â”‚   â”œâ”€â”€ extractServices()            # Service offerings extraction
â”‚   â”œâ”€â”€ extractEvents()              # Event data extraction
â”‚   â”œâ”€â”€ extractReviews()             # Review and rating extraction
â”‚   â”œâ”€â”€ extractMedia()               # Image and video extraction
â”‚   â”œâ”€â”€ extractTables()              # Table data extraction
â”‚   â”œâ”€â”€ extractForms()               # Form and interactive elements
â”‚   â”œâ”€â”€ createChunks()               # Content chunking for KB
â”‚   â””â”€â”€ storePageContent()           # S3 storage orchestration
â”‚
â”œâ”€â”€ ğŸ—ºï¸ WebsiteCrawler.js
â”‚   â”œâ”€â”€ discoverAllPages()           # URL discovery orchestrator
â”‚   â”œâ”€â”€ discoverFromSitemap()        # Sitemap XML parsing
â”‚   â”œâ”€â”€ crawlPages()                 # Internal link discovery
â”‚   â”œâ”€â”€ sanitizeUrl()                # URL validation and cleaning
â”‚   â””â”€â”€ filterUrls()                 # Duplicate removal and filtering
â”‚
â”œâ”€â”€ â˜ï¸ S3StorageService.js
â”‚   â”œâ”€â”€ storeRawContent()            # Raw HTML storage
â”‚   â”œâ”€â”€ storeProcessedContent()      # JSON chunk storage
â”‚   â”œâ”€â”€ storeStructuredData()        # Organized data storage
â”‚   â”œâ”€â”€ storeMediaMetadata()         # Media information storage
â”‚   â”œâ”€â”€ generateMetadata()           # Scraping metadata creation
â”‚   â””â”€â”€ uploadToS3()                 # AWS S3 upload handler
â”‚
â”œâ”€â”€ ğŸ§  BedrockService.js
â”‚   â”œâ”€â”€ queryKnowledgeBase()         # RAG query processing
â”‚   â”œâ”€â”€ handleSession()              # Session management
â”‚   â””â”€â”€ formatResponse()             # Response formatting
â”‚
â””â”€â”€ ğŸ”„ KnowledgeBaseSync.js
    â”œâ”€â”€ syncKnowledgeBase()          # Trigger ingestion jobs
    â”œâ”€â”€ checkSyncStatus()            # Monitor ingestion progress
    â””â”€â”€ handleSyncErrors()           # Error handling and retry
```

---

## ğŸ“Š Data Flow Detailed Breakdown

### 1. Request Processing Flow

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant API
    participant ScrapingService
    participant WebsiteCrawler
    participant S3Storage
    participant Bedrock

    User->>Frontend: Input URL
    Frontend->>Frontend: Validate URL format
    Frontend->>API: POST /api/scraping/crawl
    API->>API: Rate limiting check
    API->>API: Input validation
    API->>ScrapingService: crawlAndScrapeWebsite()
    
    ScrapingService->>WebsiteCrawler: discoverAllPages()
    WebsiteCrawler->>WebsiteCrawler: Parse sitemaps
    WebsiteCrawler->>WebsiteCrawler: Crawl internal links
    WebsiteCrawler-->>ScrapingService: Return URL list
    
    loop For each URL batch
        ScrapingService->>ScrapingService: Launch browser pool
        ScrapingService->>ScrapingService: Extract content
        ScrapingService->>S3Storage: Store data
        S3Storage-->>ScrapingService: Confirm storage
    end
    
    ScrapingService->>Bedrock: Trigger sync
    Bedrock-->>ScrapingService: Sync initiated
    ScrapingService-->>API: Return results
    API-->>Frontend: JSON response
    Frontend-->>User: Display results
```

### 2. Content Extraction Flow

```
ğŸ“„ HTML INPUT
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CHEERIO PARSER  â”‚
â”‚ Remove scripts  â”‚
â”‚ Clean content   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ PARALLEL        â”‚
â”‚ EXTRACTORS      â”‚
â”‚ (18+ types)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                EXTRACTION RESULTS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ STRUCTURED DATA â”‚ MEDIA CONTENT   â”‚ INTERACTIVE ELEMENTS â”‚
â”‚ â€¢ Products      â”‚ â€¢ Images        â”‚ â€¢ Forms             â”‚
â”‚ â€¢ Pricing       â”‚ â€¢ Videos        â”‚ â€¢ Buttons           â”‚
â”‚ â€¢ Services      â”‚ â€¢ Audio         â”‚ â€¢ Links             â”‚
â”‚ â€¢ Events        â”‚ â€¢ Metadata      â”‚ â€¢ Navigation        â”‚
â”‚ â€¢ Reviews       â”‚                 â”‚                     â”‚
â”‚ â€¢ Locations     â”‚                 â”‚                     â”‚
â”‚ â€¢ Contacts      â”‚                 â”‚                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ TEXT CONTENT    â”‚ TABLE DATA      â”‚ METADATA            â”‚
â”‚ â€¢ Full text     â”‚ â€¢ Headers       â”‚ â€¢ Title             â”‚
â”‚ â€¢ Headings      â”‚ â€¢ Rows          â”‚ â€¢ Description       â”‚
â”‚ â€¢ Paragraphs    â”‚ â€¢ Captions      â”‚ â€¢ Keywords          â”‚
â”‚ â€¢ Lists         â”‚ â€¢ Data cells    â”‚ â€¢ Author            â”‚
â”‚ â€¢ Descriptions  â”‚                 â”‚ â€¢ Language          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CHUNK CREATION  â”‚
â”‚ Text chunking   â”‚
â”‚ Metadata attach â”‚
â”‚ Hash generation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. AWS Storage Flow

```
ğŸ“Š EXTRACTED DATA
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STORAGE ROUTER  â”‚
â”‚ Categorize by   â”‚
â”‚ content type    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    S3 STORAGE PATHS                          â”‚
â”‚                                                              â”‚
â”‚  raw/domain/date/hash_raw.html      â”€â”€â–º ğŸ“„ Original HTML    â”‚
â”‚  processed/domain/date/hash.json    â”€â”€â–º âš¡ Processed chunks â”‚
â”‚  structured/domain/date/            â”€â”€â–º ğŸ—ï¸ Organized data   â”‚
â”‚  â”œâ”€â”€ hash_products.json                                     â”‚
â”‚  â”œâ”€â”€ hash_pricing.json                                      â”‚
â”‚  â”œâ”€â”€ hash_services.json                                     â”‚
â”‚  â””â”€â”€ hash_events.json                                       â”‚
â”‚  media/domain/date/hash_media.json  â”€â”€â–º ğŸ¨ Media metadata   â”‚
â”‚  tables/domain/date/hash_tables.json â”€â”€â–º ğŸ“Š Table data      â”‚
â”‚  metadata/domain/date/              â”€â”€â–º ğŸ“‹ Scraping logs    â”‚
â”‚  â”œâ”€â”€ hash_metadata.json                                     â”‚
â”‚  â””â”€â”€ scraping-log.json                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BEDROCK TRIGGER â”‚
â”‚ Start ingestion â”‚
â”‚ job for new     â”‚
â”‚ content         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4. Knowledge Base Query Flow

```
ğŸ’¬ USER QUERY: "What products are available?"
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ QUERY PROCESSOR â”‚
â”‚ Validate input  â”‚
â”‚ Session check   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ VECTOR SEARCH   â”‚
â”‚ Convert query   â”‚
â”‚ to embeddings   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OPENSEARCH      â”‚
â”‚ Find similar    â”‚
â”‚ vectors in KB   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONTEXT         â”‚
â”‚ RETRIEVAL       â”‚
â”‚ Top 5 chunks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AI GENERATION   â”‚
â”‚ Claude/GPT      â”‚
â”‚ with context    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
ğŸ“ RESPONSE: "Based on the scraped data, the following products are available: [detailed list with prices and descriptions]"
```

---

## ğŸ”„ Service Integration Points

### API Endpoint Mapping

```
ğŸŒ API ENDPOINTS
â”œâ”€â”€ POST /api/scraping/single
â”‚   â”œâ”€â”€ Input: { url, options }
â”‚   â”œâ”€â”€ Process: Single page scraping
â”‚   â””â”€â”€ Output: { success, data, metadata }
â”‚
â”œâ”€â”€ POST /api/scraping/crawl
â”‚   â”œâ”€â”€ Input: { url, crawlOptions }
â”‚   â”œâ”€â”€ Process: Full website crawling
â”‚   â””â”€â”€ Output: { success, crawlId, summary }
â”‚
â”œâ”€â”€ POST /api/chat/query
â”‚   â”œâ”€â”€ Input: { query, sessionId }
â”‚   â”œâ”€â”€ Process: Knowledge base search
â”‚   â””â”€â”€ Output: { success, answer, citations }
â”‚
â”œâ”€â”€ GET /api/scraping/status/:crawlId
â”‚   â”œâ”€â”€ Input: crawlId parameter
â”‚   â”œâ”€â”€ Process: Check crawling progress
â”‚   â””â”€â”€ Output: { status, progress, results }
â”‚
â””â”€â”€ GET /health
    â”œâ”€â”€ Input: None
    â”œâ”€â”€ Process: System health check
    â””â”€â”€ Output: { status, timestamp, services }
```

### Error Handling Flow

```
âŒ ERROR TYPES & HANDLING

ğŸ•·ï¸ SCRAPING ERRORS
â”œâ”€â”€ Navigation timeout â”€â”€â–º Retry with longer timeout
â”œâ”€â”€ Page load failure â”€â”€â–º Skip URL, log error
â”œâ”€â”€ Content extraction â”€â”€â–º Fallback extractors
â””â”€â”€ Browser crash â”€â”€â–º Restart browser pool

â˜ï¸ AWS ERRORS
â”œâ”€â”€ S3 upload failure â”€â”€â–º Retry with backoff
â”œâ”€â”€ Bedrock timeout â”€â”€â–º Queue for later sync
â”œâ”€â”€ Permission denied â”€â”€â–º Log and alert admin
â””â”€â”€ Rate limiting â”€â”€â–º Implement exponential backoff

ğŸ” QUERY ERRORS
â”œâ”€â”€ Invalid input â”€â”€â–º Return validation error
â”œâ”€â”€ Knowledge base unavailable â”€â”€â–º Fallback response
â”œâ”€â”€ Model timeout â”€â”€â–º Retry with shorter context
â””â”€â”€ Session expired â”€â”€â–º Create new session

ğŸŒ API ERRORS
â”œâ”€â”€ Rate limit exceeded â”€â”€â–º Return 429 status
â”œâ”€â”€ Invalid request â”€â”€â–º Return 400 with details
â”œâ”€â”€ Server error â”€â”€â–º Return 500, log details
â””â”€â”€ Service unavailable â”€â”€â–º Return 503 status
```

---

## ğŸ“ˆ Performance & Scaling Considerations

### Concurrency Management

```
ğŸ”„ CONCURRENT PROCESSING

Browser Pool Management:
â”œâ”€â”€ Max 3 browser instances
â”œâ”€â”€ Page pool per browser (5 pages)
â”œâ”€â”€ Automatic cleanup on timeout
â””â”€â”€ Memory monitoring & restart

Batch Processing:
â”œâ”€â”€ Default batch size: 3 URLs
â”œâ”€â”€ Configurable delay between batches
â”œâ”€â”€ Progress tracking and reporting
â””â”€â”€ Error isolation per batch

S3 Upload Optimization:
â”œâ”€â”€ Parallel uploads for different content types
â”œâ”€â”€ Compression for large text content
â”œâ”€â”€ Retry logic with exponential backoff
â””â”€â”€ Connection pooling and reuse

Knowledge Base Sync:
â”œâ”€â”€ Asynchronous ingestion jobs
â”œâ”€â”€ Status monitoring and reporting
â”œâ”€â”€ Incremental sync for new content
â””â”€â”€ Error handling and retry
```

### Resource Management

```
ğŸ’¾ MEMORY & CPU OPTIMIZATION

Browser Resource Management:
â”œâ”€â”€ Headless mode with minimal args
â”œâ”€â”€ Disable images/CSS for text extraction
â”œâ”€â”€ Page timeout and cleanup
â””â”€â”€ Process isolation and restart

Content Processing:
â”œâ”€â”€ Stream processing for large pages
â”œâ”€â”€ Chunk-based memory allocation
â”œâ”€â”€ Garbage collection optimization
â””â”€â”€ CPU-intensive task queuing

Storage Optimization:
â”œâ”€â”€ Compression for JSON data
â”œâ”€â”€ S3 lifecycle policies
â”œâ”€â”€ Metadata indexing
â””â”€â”€ Cold storage transition
```

This comprehensive architecture documentation provides a complete understanding of how all components work together in the scraping service ecosystem!